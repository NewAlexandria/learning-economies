# NIST 800-181 (NICE)–aligned, testable hypotheses using the Learning Economies model in `/_posts/2025-09-14-AI-learning-economics.md`

## Format per hypothesis

- Work Role/Category; Specialty Area
- Statement (testable)
- Population / Intervention / Comparator
- Measures (quantitative)
- Data Sources
- KSAs Targeted (Knowledge, Skills, and Abilities)
- Related Tasks (T)
- Success Criteria

### Breadth (Multi-Subject / Multi-Degree)

1)

- Work Role/Category: OV-TEA (Training, Education & Awareness); Workforce Development
- Statement: AI scaffolding increases parallel-domain competency throughput without proficiency loss.
- Population/Intervention/Comparator: Undergrads; AI tutor + compressed curricula vs standard curricula.
- Measures: Number of distinct domains ≥3 with proficiency ≥80% in 12 weeks; time-on-task; drop rate.
- Data Sources: LMS assessments, proctored exams, time logs.
- KSAs: K: learning science; S: curriculum design; A: assess learning outcomes.
- Tasks: T: design/implement/assess training; update learning paths.
- Success: ≥2× increase in domains completed with non-inferior proficiency (±5% margin) vs control.

2)

- Work Role/Category: OV-TEA; OM (Operate & Maintain)
- Statement: Resonance prompts raise cross-domain transfer success on first attempt.
- Population/Intervention/Comparator: Bootcamp cohorts; prompted cross-domain analogies vs none.
- Measures: Transfer task pass rate; time-to-first-correct; error types.
- Data Sources: Task trackers, code submissions, rubric scoring.
- KSAs: K: cross-domain analogies; S: mapping patterns; A: apply abstractions.
- Tasks: T: create transfer activities; evaluate competency.
- Success: ≥20% absolute increase in transfer-task pass rate.

### Depth (Acceleration)

3)

- Work Role/Category: OV-TEA; SP-DEV (Software Development)
- Statement: AI amplification reduces time-to-competence to the 90th percentile in a single domain.
- Population/Intervention/Comparator: New hires; guided AI practice loops vs traditional mentorship.
- Measures: Days to 90th percentile on standardized domain exam; retention at 30/90 days.
- Data Sources: Exam records, spaced-recall quizzes.
- KSAs: K: domain foundations; S: deliberate practice; A: rapid concept integration.
- Tasks: T: develop accelerated pathways; validate mastery.
- Success: ≥40% reduction in days-to-competence without retention loss (±5%).

4)

- Work Role/Category: OV-TEA
- Statement: Compression (dense representations) improves long-term retention at equal study time.
- Population/Intervention/Comparator: Continuing-ed learners; compressed notes + active recall vs standard notes.
- Measures: 30/90-day retention; effect size (Cohen’s d); identical time budgets.
- Data Sources: Low-stakes quizzes; spaced testing logs.
- KSAs: K: memory systems; S: materials design; A: evaluate retention.
- Tasks: T: produce/maintain materials; measure outcomes.
- Success: d ≥ 0.5 improvement at 30 and 90 days.

### Subset (Retraining / Mobility)

5)

- Work Role/Category: OV-TEA; AN (Analyze)
- Statement: Resonance-mapped retraining halves time-to-employable proficiency in new field.
- Population/Intervention/Comparator: Mid-career pivoters; personalized resonance map vs generic curriculum.
- Measures: Weeks to pass industry certification; time-to-first independent contribution.
- Data Sources: Cert records, PR review timestamps.
- KSAs: K: target-field core; S: transfer planning; A: adapt prior skills.
- Tasks: T: map prior-to-target KSAs; tailor retraining.
- Success: ≥50% reduction in time-to-cert and time-to-first-contribution.

6)

- Work Role/Category: OV-TEA; OM
- Statement: Liquidity tracking (skills convertibility) predicts pivot success better than years of experience.
- Population/Intervention/Comparator: Internal mobility candidates; model with liquidity index vs baseline seniority model.
- Measures: AUC/accuracy of success prediction; calibration; actual pivot success at 6 months.
- Data Sources: HRIS, skills inventory, performance reviews.
- KSAs: K: workforce analytics; S: feature engineering; A: interpret models.
- Tasks: T: analyze workforce patterns; recommend mobility paths.
- Success: AUC improvement ≥0.1 vs baseline.

### Superset (Field Reinvention / Obviation)

7)

- Work Role/Category: OV (Oversee & Govern); SP (Securely Provision)
- Statement: Cross-domain synthesis teams produce more field-obviating proposals than mono-domain teams.
- Population/Intervention/Comparator: R&D squads; ≥3-domain synthesis + AI ideation vs single-domain teams.
- Measures: Count of proposals rated “obviating” by blinded panel; downstream adoption within 12 months.
- Data Sources: Proposal corpus, panel ratings, adoption metrics.
- KSAs: K: innovation patterns; S: synthesis facilitation; A: reframe problem spaces.
- Tasks: T: run innovation sprints; evaluate disruptive potential.
- Success: ≥2× increase in obviating proposals and ≥1.5× adoption.

8)

- Work Role/Category: OV; PR (Protect & Defend)
- Statement: Superset prototypes reduce legacy-task demand by >60% within pilot scope.
- Population/Intervention/Comparator: Ops group; deploy AI system replacing legacy workflows vs pre-pilot baseline.
- Measures: % reduction in legacy task hours; error rate; incident rate.
- Data Sources: Time tracking, QA logs, incident registry.
- KSAs: K: process redesign; S: automation; A: risk-aware deployment.
- Tasks: T: architect/implement new workflows; retire obsolete controls.
- Success: ≥60% time reduction with non-inferior error/incident rates.

### Network-form (Multi-Scale Routing)

9)

- Work Role/Category: AN (Analyze); PR-CDA (Cyber Defense Analysis)
- Statement: Multi-scale routing assistance shortens average path length from signal to systemic insight.
- Population/Intervention/Comparator: Analysts; AI path suggestions linking micro→macro vs standard tools.
- Measures: Steps/time from alert to root cause + policy implication; correctness.
- Data Sources: Case systems, time stamps, adjudications.
- KSAs: K: system topology; S: graph reasoning; A: scale traversal.
- Tasks: T: analyze multi-source data; produce cross-scale findings.
- Success: ≥30% reduction in steps/time; no drop in correctness.

10)

- Work Role/Category: OV-TEA; AN
- Statement: Network compression (semantic routing protocols) increases discovery of emergent patterns.
- Population/Intervention/Comparator: Research teams; compressed knowledge graph interfaces vs flat wikis.
- Measures: New cross-scale insights per month; novelty score (expert panel); replication within 60 days.
- Data Sources: Lab notebook mining, citation graphs.
- KSAs: K: knowledge graphs; S: query design; A: pattern detection.
- Tasks: T: curate and query enterprise knowledge; disseminate findings.
- Success: ≥50% increase in validated emergent insights.

### Meta-Factors

11. Scaffolding

- Work Role/Category: OV-TEA
- Statement: Layered scaffolding reduces cognitive load peaks during mastery ramps.
- Population/Intervention/Comparator: Depth cohorts; layered scaffolds (worked→faded) vs unlayered aids.
- Measures: NASA-TLX peaks; error spikes; dropout.
- Data Sources: Experience sampling; telemetry.
- KSAs: K: cognitive load theory; S: scaffold design; A: progressive disclosure.
- Tasks: T: structure learning pathways; monitor learner load.
- Success: ≥25% reduction in peak TLX; ≥15% fewer error spikes.

12. Redundancy

- Work Role/Category: OV (Govern); OM
- Statement: Redundant skill overlap improves resilience to superset disruptions.
- Population/Intervention/Comparator: Departments; deliberate overlap vs minimal overlap.
- Measures: MTTR after obviation; delivery variance; role survivability.
- Data Sources: Incident logs, OKRs, HR transitions.
- KSAs: K: resilience engineering; S: workforce planning; A: design for continuity.
- Tasks: T: staff capability portfolios; execute continuity plans.
- Success: ≥30% lower MTTR; ≥20% lower variance post-disruption.

13. Inheritance

- Work Role/Category: OV-TEA
- Statement: Codified inheritance (playbooks + exemplars) increases Breadth and Subset velocities.
- Population/Intervention/Comparator: New cohorts; codified inheritance vs ad-hoc mentoring.
- Measures: Parallel pipelines completed; pivot time; error rates.
- Data Sources: LMS, HR mobility, QA.
- KSAs: K: knowledge management; S: playbook authoring; A: curate exemplars.
- Tasks: T: capture institutional knowledge; maintain repositories.
- Success: Breadth ↑ ≥30%; pivot time ↓ ≥30% with non-inferior QA.

14. Liquidity

- Work Role/Category: OV (Govern)
- Statement: Higher Competency Liquidity Ratios predict organizational adaptability.
- Population/Intervention/Comparator: Divisions; liquidity-indexed staffing vs baseline.
- Measures: Time-to-staff for new initiative; success rate at 6 months.
- Data Sources: Skills graph; project outcomes.
- KSAs: K: org design; S: skills graphing; A: portfolio balancing.
- Tasks: T: plan workforce composition; allocate talent.
- Success: ≥25% faster staffing; ≥10% higher success rate.

### Common evaluation protocol

- Design: RCT or matched cohort where feasible; pre-register metrics and analysis.
- Stats: Non-inferiority/equivalence where appropriate; effect sizes; multiplicity control.
- Ethics: Privacy-preserving logs; IRB where required; minimize bias.

—

- These hypotheses map the five Learning Economies and meta-factors to NICE-style KSATs and roles, with concrete, measurable outcomes suitable for pilots or A/B tests.
